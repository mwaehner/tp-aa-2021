{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46792a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install --user sklearn\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "#! pip install --user pandas\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6f666",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Levantamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6522506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Donald Trump Sends Out Embarrassing New Year’...\n",
      "1         Drunk Bragging Trump Staffer Started Russian ...\n",
      "2         Sheriff David Clarke Becomes An Internet Joke...\n",
      "3         Trump Is So Obsessed He Even Has Obama’s Name...\n",
      "4         Pope Francis Just Called Out Donald Trump Dur...\n",
      "                               ...                        \n",
      "44893    'Fully committed' NATO backs new U.S. approach...\n",
      "44894    LexisNexis withdrew two products from Chinese ...\n",
      "44895    Minsk cultural hub becomes haven from authorities\n",
      "44896    Vatican upbeat on possibility of Pope Francis ...\n",
      "44897    Indonesia to buy $1.14 billion worth of Russia...\n",
      "Name: title, Length: 44898, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake = pd.read_csv(\"../archive/Fake.csv\")\n",
    "true = pd.read_csv(\"../archive/True.csv\")\n",
    "\n",
    "# ponemos los dos en uno\n",
    "fake[\"label\"] = 1\n",
    "true[\"label\"] = 0\n",
    "df = pd.concat([fake, true], ignore_index = True)\n",
    "print(df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d4173",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento: limpiamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fb8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    # agregar otras...\n",
    "    return text\n",
    "\n",
    "df.title = df.title.map(clean_text)\n",
    "df.text = df.text.map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab825996",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Vectorizamos el texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbc201",
   "metadata": {},
   "source": [
    "Hicimos la experimentación utilizando dos vectorizadores de texto distintos:\n",
    "- Count Vectorizer, que simplemente cuenta la cantidad de apariciones de cada palabra.\n",
    "- Term Frequency Inverse Document Frequency, que incrementa proporcionalmente con la cantidad de apariciones de la palabra pero contrarresta con el número de documentos en el que está presente, permitiendo así que las palabras demasiado frecuentes y sin valor semántico no sean un problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec85c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_COUNT_VECTORIZER = True # Con este parametro controlamos cual vectorizador usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f4a727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>administration</th>\n",
       "      <th>admits</th>\n",
       "      <th>adviser</th>\n",
       "      <th>agency</th>\n",
       "      <th>ahead</th>\n",
       "      <th>aid</th>\n",
       "      <th>aide</th>\n",
       "      <th>...</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>wow</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       act  action  ad  administration  admits  adviser  agency  ahead  aid  \\\n",
       "0        0       0   0               0       0        0       0      0    0   \n",
       "1        0       0   0               0       0        0       0      0    0   \n",
       "2        0       0   0               0       0        0       0      0    0   \n",
       "3        0       0   0               0       0        0       0      0    0   \n",
       "4        0       0   0               0       0        0       0      0    0   \n",
       "...    ...     ...  ..             ...     ...      ...     ...    ...  ...   \n",
       "44893    0       0   0               0       0        0       0      0    0   \n",
       "44894    0       0   0               0       0        0       0      0    0   \n",
       "44895    0       0   0               0       0        0       0      0    0   \n",
       "44896    0       0   0               0       0        0       0      0    0   \n",
       "44897    0       0   0               0       0        0       0      0    0   \n",
       "\n",
       "       aide  ...  wont  work  workers  working  world  wow  year  years  york  \\\n",
       "0         0  ...     0     0        0        0      0    0     0      1     0   \n",
       "1         0  ...     0     0        0        0      0    0     0      0     0   \n",
       "2         0  ...     0     0        0        0      0    0     0      0     0   \n",
       "3         0  ...     0     0        0        0      0    0     0      0     0   \n",
       "4         0  ...     0     0        0        0      0    0     0      0     0   \n",
       "...     ...  ...   ...   ...      ...      ...    ...  ...   ...    ...   ...   \n",
       "44893     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "44894     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "44895     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "44896     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "44897     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "\n",
       "       young  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "44893      0  \n",
       "44894      0  \n",
       "44895      0  \n",
       "44896      0  \n",
       "44897      0  \n",
       "\n",
       "[44898 rows x 495 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removemos palabras con muy alta o muy baja frecuencia. ademas, removemos las \"stop words\" del inglés\n",
    "# (palabras como 'the', 'a', 'he', 'her', etc.)\n",
    "def vectorize_text(dataframe):\n",
    "    MAX_FREQ_THRESHOLD = 0.8\n",
    "    MIN_FREQ_THRESHOLD = 0.003\n",
    "    kwargs = {\n",
    "        'stop_words': 'english',\n",
    "        'max_df': MAX_FREQ_THRESHOLD,\n",
    "        'min_df': MIN_FREQ_THRESHOLD\n",
    "    }\n",
    "    # DOCS: \n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    vect = CountVectorizer(**kwargs) if USE_COUNT_VECTORIZER else TfidfVectorizer(**kwargs)\n",
    "    data_vectorized_titles = vect.fit_transform(dataframe.title)\n",
    "    # print(cv.get_feature_names())  # vocabulario\n",
    "    # print(len(cv.get_feature_names())) # tamaño del vocabulario\n",
    "    data_dtm = pd.DataFrame(data_vectorized_titles.toarray(), columns=vect.get_feature_names())\n",
    "    data_dtm.index = dataframe.index\n",
    "    return data_dtm\n",
    "\n",
    "data_dtm = vectorize_text(df)\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d894e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e789e0",
   "metadata": {},
   "source": [
    "### 4.1 ¿Cuáles son las palabras más frecuentes en los títulos de cada tipo de noticia?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fd93d",
   "metadata": {},
   "source": [
    "#### Palabras más frecuentes en las noticias falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11a1f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 7216),\n",
       " ('video', 3229),\n",
       " ('watch', 1890),\n",
       " ('obama', 1809),\n",
       " ('hillary', 1765),\n",
       " ('trumps', 1467),\n",
       " ('just', 1399),\n",
       " ('president', 1075),\n",
       " ('clinton', 964),\n",
       " ('new', 893)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fake = data_dtm[:len(fake)]\n",
    "data_fake = data_fake.transpose()\n",
    "data_fake_top = data_fake.sum(axis=1).sort_values(ascending=False)[:60]\n",
    "fake_dict = list(zip(data_fake_top.index, map(round, data_fake_top.values)))\n",
    "fake_dict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffccaea",
   "metadata": {},
   "source": [
    "#### Palabras más frecuentes en las noticias verdaderas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed352ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 4734),\n",
       " ('house', 1437),\n",
       " ('north', 924),\n",
       " ('new', 875),\n",
       " ('white', 815),\n",
       " ('korea', 804),\n",
       " ('russia', 804),\n",
       " ('senate', 739),\n",
       " ('court', 711),\n",
       " ('trumps', 683)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_true = data_dtm[len(fake):len(fake)+len(true)]\n",
    "data_true = data_true.transpose()\n",
    "data_true_top = data_true.sum(axis=1).sort_values(ascending=False)[:60]\n",
    "true_dict = list(zip(data_true_top.index, map(round, data_true_top.values)))\n",
    "\n",
    "\"\"\"\n",
    "Esto es truchisimo pero estamos sacando la palabra que mas aparece que es 'says'\n",
    "\"\"\"\n",
    "true_dict.pop(1) \n",
    "true_dict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a191207",
   "metadata": {},
   "source": [
    "#### Y para visualizarlo un poco más lindo, usemos un WordCloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c667748",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6268500608b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m wc = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n\u001b[1;32m      4\u001b[0m                max_font_size=150, random_state=42, collocations=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42, collocations=False)\n",
    "\n",
    "# Reset the output dimensions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_true_str = ''.join([(x[0] + ' ')*x[1] for x in true_dict])\n",
    "data_fake_str = ''.join([(x[0] + ' ')*x[1] for x in fake_dict])\n",
    "plt.rcParams['figure.figsize'] = [16, 6]\n",
    "titles = ['Real news', 'Fake news']\n",
    "data = [data_true_str, data_fake_str]\n",
    "# Create subplots for each comedian\n",
    "for index, data_str in enumerate(data):\n",
    "    wc.generate(data[index])\n",
    "    \n",
    "    plt.subplot(1,2, index+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(titles[index])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185666e",
   "metadata": {},
   "source": [
    "- Las palabras que vemos tienen todas un buen valor semántico, indicando que el preprocesamiento del texto que hicimos es bueno. \n",
    "- Parecería que las noticias falsas tienen que ver con temas sociales\n",
    "- Y que las noticias verdaderas hablan más de economía y política internacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50787803",
   "metadata": {},
   "source": [
    "## 5. Downsample del dataset\n",
    "Hacemos esto para que la experimentación dure menos, pero lo vamos a desactivar para reportar los resultados finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48bba1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>administration</th>\n",
       "      <th>admits</th>\n",
       "      <th>adviser</th>\n",
       "      <th>agency</th>\n",
       "      <th>ahead</th>\n",
       "      <th>aid</th>\n",
       "      <th>aide</th>\n",
       "      <th>...</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>wow</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41229</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25907</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26443</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       act  action  ad  administration  admits  adviser  agency  ahead  aid  \\\n",
       "15795    0       0   0               0       0        0       0      0    0   \n",
       "860      0       0   0               0       0        0       0      0    0   \n",
       "5390     0       0   0               0       0        0       0      0    0   \n",
       "21575    0       0   0               0       0        0       0      0    0   \n",
       "11964    0       0   0               0       0        0       0      0    0   \n",
       "...    ...     ...  ..             ...     ...      ...     ...    ...  ...   \n",
       "41229    0       0   0               0       0        0       0      0    0   \n",
       "27157    0       0   0               0       0        0       0      0    0   \n",
       "25907    0       0   0               0       0        0       0      0    0   \n",
       "26443    0       0   0               0       0        0       0      0    0   \n",
       "24340    0       0   0               0       0        0       0      0    0   \n",
       "\n",
       "       aide  ...  wont  work  workers  working  world  wow  year  years  york  \\\n",
       "15795     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "860       0  ...     0     0        0        0      0    0     0      0     0   \n",
       "5390      0  ...     0     0        0        0      0    0     0      0     0   \n",
       "21575     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "11964     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "...     ...  ...   ...   ...      ...      ...    ...  ...   ...    ...   ...   \n",
       "41229     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "27157     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "25907     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "26443     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "24340     0  ...     0     0        0        0      0    0     0      0     0   \n",
       "\n",
       "       young  \n",
       "15795      0  \n",
       "860        0  \n",
       "5390       0  \n",
       "21575      0  \n",
       "11964      0  \n",
       "...      ...  \n",
       "41229      0  \n",
       "27157      0  \n",
       "25907      0  \n",
       "26443      0  \n",
       "24340      0  \n",
       "\n",
       "[8000 rows x 495 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametros de config\n",
    "DO_DOWNSAMPLE = True\n",
    "DOWNSAMPLING_SIZE=8000\n",
    "\n",
    "if DO_DOWNSAMPLE:\n",
    "    dtm_fake_downsampled = resample(data_fake.transpose(), n_samples=int(DOWNSAMPLING_SIZE/2), random_state=42)\n",
    "    dtm_true_downsampled = resample(data_true.transpose(), n_samples=int(DOWNSAMPLING_SIZE/2), random_state=42)\n",
    "\n",
    "dtm_downsampled = pd.concat([dtm_fake_downsampled, dtm_true_downsampled])\n",
    "dtm_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701ee0a",
   "metadata": {},
   "source": [
    "## 6. Partimos el dataset en un conjunto de training y otro de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01b0d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n"
     ]
    }
   ],
   "source": [
    "if DO_DOWNSAMPLE:\n",
    "    Y = np.array([1]*int(DOWNSAMPLING_SIZE/2) + [0]*int(DOWNSAMPLING_SIZE/2))\n",
    "    X = dtm_downsampled.to_numpy()\n",
    "else:\n",
    "    Y = df['label'].to_numpy()\n",
    "    X = data_dtm.to_numpy()\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "#Si estamos usando el Count vectorizer debemos normalizar el texto. Notar que vectorizamos el test sin saber su contenido\n",
    "if (USE_COUNT_VECTORIZER):\n",
    "    scaler = MinMaxScaler() #se puede poner el otro\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.90)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958e5f4",
   "metadata": {},
   "source": [
    "## 7. Y la parte más jugosa: técnicas de NLP para clasificar las noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a8b91",
   "metadata": {},
   "source": [
    "### 7.1: k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8cfc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bceb788",
   "metadata": {},
   "source": [
    "#### 7.1.1: cross validation para hallar el mejor \"k\" de k-nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4f15ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ................n_neighbors=1, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=1, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=1, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=1, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=1, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=1, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=1, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=1, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=1, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=1, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ................n_neighbors=2, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=2, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=2, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=2, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=2, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ...............n_neighbors=2, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=2, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=2, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=2, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=2, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ................n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ................n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ................n_neighbors=4, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=4, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=4, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=4, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=4, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ...............n_neighbors=4, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=4, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=4, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=4, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=4, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ................n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ................n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END ...............n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END ...............n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "Best accuracy is 0.7771428571428571\n",
      "For parameters {'n_neighbors': 3, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 6),\n",
    "             'weights': ['uniform', 'distance'], # Indica si considerar la distancia en la prediccion\n",
    "             'p': [1, 2] # 1 = Manhattan, 2 = Euclidea\n",
    "             }\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5, verbose=2)\n",
    "knn_gscv.fit(X_train, Y_train)\n",
    "\n",
    "best_accuracy = knn_gscv.best_score_\n",
    "best_params = knn_gscv.best_params_\n",
    "print(\"Best accuracy is\", best_accuracy)\n",
    "print(\"For parameters\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c8aba-bd29-4693-9745-ae022a48249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy para cada tupla de parametros')\n",
    "list(zip(knn_gscv.cv_results_['params'], knn_gscv.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f14dc",
   "metadata": {},
   "source": [
    "#### 7.1.2: score obtenido para k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f70ac33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891666666666667"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_knn = KNeighborsClassifier(**best_params)\n",
    "tuned_knn.fit(X_train, Y_train)\n",
    "tuned_knn.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c37058",
   "metadata": {},
   "source": [
    "### 7.2: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8407a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(max_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f80c2",
   "metadata": {},
   "source": [
    "#### 7.2.2: cross validation para hallar los mejores hiperparámetros de la Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5e174f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   2.9s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   2.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   2.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   2.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   2.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   1.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   1.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   1.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=scale, kernel=poly; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END ...................C=1, gamma=scale, kernel=sigmoid; total time=   1.6s\n",
      "Best accuracy is 0.8619642857142857\n",
      "For parameters {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'C': [1], # poner [0.5, 1, 10, 100] para exp final\n",
    "    'gamma': ['scale'], # poner ['scale', 1, 0.1, 0.01, 0.001, 0.0001] para exp final\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n",
    "]\n",
    "#Default values are C=1 and gamma='scale'\n",
    "svm_gscv = GridSearchCV(\n",
    "    svm_classifier,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2\n",
    ")\n",
    "svm_gscv.fit(X_train, Y_train)\n",
    "\n",
    "best_accuracy = svm_gscv.best_score_\n",
    "best_params = svm_gscv.best_params_\n",
    "print(\"Best accuracy is\", best_accuracy)\n",
    "print(\"For parameters\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bff9e4cc-d2a2-425f-a88a-a7f3cb718bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para cada tupla de parametros\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, 0.8619642857142857),\n",
       " ({'C': 1, 'gamma': 'scale', 'kernel': 'linear'}, 0.8591071428571428),\n",
       " ({'C': 1, 'gamma': 'scale', 'kernel': 'poly'}, 0.8485714285714285),\n",
       " ({'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}, 0.8476785714285715)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy para cada tupla de parametros')\n",
    "list(zip(svm_gscv.cv_results_['params'], svm_gscv.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51a509",
   "metadata": {},
   "source": [
    "#### 7.2.2: score obtenido para nuestra Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "32be1bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8683333333333333"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_svm = svm.SVC(**best_params)\n",
    "tuned_svm.fit(X_train, Y_train)\n",
    "tuned_svm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e944819",
   "metadata": {},
   "source": [
    "### 7.3: Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9046a368-4b6a-4965-b163-33f7021d080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae48365-913b-400b-b22c-dd47dac7d913",
   "metadata": {},
   "source": [
    "#### 7.3.2: cross validation para hallar los mejores hiperparámetros de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf0c82-7024-4bd0-8db0-afdbd92400d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.0001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.000774263682681127, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.000774263682681127, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.000774263682681127, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.000774263682681127, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.000774263682681127, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.000774263682681127, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.000774263682681127, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.000774263682681127, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.000774263682681127, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.000774263682681127, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.005994842503189409, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.005994842503189409, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.005994842503189409, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.005994842503189409, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.005994842503189409, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.005994842503189409, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.005994842503189409, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.005994842503189409, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.005994842503189409, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.005994842503189409, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.046415888336127774, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.3593813663804626, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.3593813663804626, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.3593813663804626, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=2.782559402207126, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=2.782559402207126, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=2.782559402207126, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=2.782559402207126, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=2.782559402207126, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=2.782559402207126, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=2.782559402207126, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=2.782559402207126, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=2.782559402207126, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=2.782559402207126, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=21.54434690031882, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ..C=21.54434690031882, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=21.54434690031882, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=21.54434690031882, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=21.54434690031882, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=21.54434690031882, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=21.54434690031882, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=21.54434690031882, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=21.54434690031882, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=21.54434690031882, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=166.81005372000558, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=166.81005372000558, penalty=l1, solver=liblinear; total time=   3.4s\n",
      "[CV] END .C=166.81005372000558, penalty=l1, solver=liblinear; total time=   3.7s\n",
      "[CV] END .C=166.81005372000558, penalty=l1, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=166.81005372000558, penalty=l1, solver=liblinear; total time=   9.7s\n",
      "[CV] END .C=166.81005372000558, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=166.81005372000558, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=166.81005372000558, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=166.81005372000558, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=166.81005372000558, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=1291.5496650148827, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END .C=1291.5496650148827, penalty=l1, solver=liblinear; total time=   4.2s\n",
      "[CV] END .C=1291.5496650148827, penalty=l1, solver=liblinear; total time=   4.4s\n",
      "[CV] END .C=1291.5496650148827, penalty=l1, solver=liblinear; total time=   5.1s\n",
      "[CV] END .C=1291.5496650148827, penalty=l1, solver=liblinear; total time=  14.1s\n",
      "[CV] END .C=1291.5496650148827, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END .C=1291.5496650148827, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=1291.5496650148827, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=1291.5496650148827, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=1291.5496650148827, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time=   4.0s\n",
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time=   4.8s\n",
      "[CV] END ............C=10000.0, penalty=l1, solver=liblinear; total time=   5.1s\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 10),\n",
    "    'solver' : ['liblinear']\n",
    "    }\n",
    "\n",
    "lr_gscv = GridSearchCV(\n",
    "    lr_classifier,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2\n",
    ")\n",
    "lr_gscv.fit(X_train, Y_train)\n",
    "\n",
    "best_accuracy = lr_gscv.best_score_\n",
    "best_params = lr_gscv.best_params_\n",
    "print(\"Best accuracy is\", best_accuracy)\n",
    "print(\"For parameters\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a61632-fb72-4026-84ae-ab6a4c6c77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy para cada tupla de parametros')\n",
    "list(zip(lr_gscv.cv_results_['params'], lr_gscv.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b351fa7-4ffd-424f-ac81-283c07bc4c8d",
   "metadata": {},
   "source": [
    "#### 7.3.3: score obtenido para la Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d0a12-8073-4bab-97f9-7e73e8a85ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(**best_params)\n",
    "lr.fit(X_train,Y_train)\n",
    "score_lr = lr.score(X_test, Y_test)\n",
    "score_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52b797",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641178c",
   "metadata": {},
   "source": [
    "RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c99f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ANN.ipynb\n",
    "\n",
    "epoch = 5\n",
    "learning_rate = 0.005\n",
    "\n",
    "network = [\n",
    "  fullyConnectedLayer(495, 64,'random'),\n",
    "  activationLayer(relu, relu_prime),\n",
    "  fullyConnectedLayer(64, 32,'random'),\n",
    "  activationLayer(relu, relu_prime),\n",
    "  fullyConnectedLayer(32, 16,'random'),\n",
    "  activationLayer(relu, relu_prime),\n",
    "  fullyConnectedLayer(16, 1,'random'),\n",
    "  activationLayer(sigmoid, sigmoid_prime),\n",
    "\n",
    "  ]\n",
    "X_train=X_train.reshape((5600, 1,495))\n",
    "compile_(network,epoch,learning_rate,X_train,Y_train)\n",
    "ratio = sum([y == np.round(predict(network, x)[0][0]) for x, y in zip(X_test, Y_test)]) / len(X_test)\n",
    "error = sum([mse(y, predict(network, x)) for x, y in zip(X_test, Y_test)]) / len(X_test)\n",
    "print('ratio: %.2f' % ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17b107f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\n\\n- Probar con otros valores (idealmente no arbitrarios) de MIN_FREQUENCY y MAX_FREQUENCY\\n- Hacer grafiquitos lindos\\n- Probar usando solo los títulos de la noticia, ignorar el texto.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "- Probar con otros valores (idealmente no arbitrarios) de MIN_FREQUENCY y MAX_FREQUENCY\n",
    "- Hacer grafiquitos lindos\n",
    "- Probar usando solo los títulos de la noticia, ignorar el texto. (DONE)\n",
    "- Experimentar variando el max_iter tanto de SVM como de LogisticRegression\n",
    "- Entender qué carajo son las iteraciones\n",
    "- Experimentar cambiando la función kernel de SVM (poly, rbf, linear, sigmoid (Sigmoid Freud))\n",
    "- Experimentar variando el tamano del conjunto de entrenamiento (train_set)\n",
    "- Por defecto SVM tiene max_iter=-1 iteraciones y parece que no termina (converge?) nunca, pero por ahora no lo corrimos\n",
    "más de 5 minutos, estaría bueno dejar corriéndolo un rato y ver si termina.\n",
    "\n",
    "Resultados para recordar:\n",
    "Hasta ahora SVM dio mejor con kernel=rbf (88,8% de accuracy con 10.000 iteraciones).\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c9531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabf54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
